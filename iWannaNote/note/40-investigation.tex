\titlespacing\section{\parindent}{28pt}{14pt} 
\section{Исследовательский раздел}
\titlespacing\section{\parindent}{28pt}{28pt} 
\titlespacing\subsection{\parindent}{14pt}{28pt}
\subsection{Условия исследований}
\titlespacing\subsection{\parindent}{28pt}{28pt}
Исследование проводилось на персональном компьютере со следующими характеристиками:

\begin{itemize}
\item процессор Apple M1 Pro \cite{m1proproc};
\item операционная система macOS Ventura 13.5.2 (22G91) \cite{ventura};
\item 32 Гб оперативной памяти.
\end{itemize}

Для определения гиперпараметров каждой модели применялся метод поиска по сетке с опорой на значение F1-меры. Разбиение данных на выборки производилось на 4 части, 1 из которых используется в качестве тестовой, результаты приводятся для каждого разбиения.

\titlespacing\subsection{\parindent}{28pt}{14pt}
\subsection{Исследование применимости моделей машинного обучения в методе распознавания суицидальных паттернов поведения человека по текстовым сообщениям}
\titlespacing\subsection{\parindent}{28pt}{28pt}

\titlespacing\subsubsection{\parindent}{14pt}{28pt}
\subsubsection{Градиентный бустинг}
\titlespacing\subsubsection{\parindent}{28pt}{28pt}

Параметры модели при применении метода векторизации <<мешок слов>>:
\begin{itemize}
	\item коэффициент обучения -- влияет на скорость обучения -- 0.5;
	\item количество классификаторов в ансамбле -- определяет количество деревьев, используемых в алгоритме -- 215;
	\item минимальное количество образцов для разбиения узла -- 5.
\end{itemize}

На рисунке \ref{img:gradientMatrBag} представлены матрицы ошибок, полученные с использованием градиентного бустинга, метод векторизации -- <<мешок слов>>.

На рисунке \ref{img:gradientMetricsBag} представлены оценки классификатора, полученные с использованием градиентного бустинга, метод векторизации -- <<мешок слов>>.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/gradientMatrBag.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием градиентного бустинга (метод векторизации -- <<мешок слов>>). }
	\label{img:gradientMatrBag}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/gradientMetricsBag.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием градиентного бустинга (метод векторизации --  <<мешок слов>>). }
	\label{img:gradientMetricsBag}
\end{figure}
\pagebreak

Параметры модели при применении векторизации BERT:
\begin{itemize}
	\item коэффициент обучения -- 0.3;
	\item количество классификаторов в ансамбле -- 245;
	\item минимальное количество образцов для разбиения узла -- 16.
\end{itemize}

На рисунке \ref{img:gradientMatrBert} представлены матрицы ошибок, полученные с использованием градиентного бустинга, метод векторизации -- BERT.

На рисунке \ref{img:gradientMetricsBert} представлены оценки классификатора, полученные с использованием градиентного бустинга, метод векторизации -- BERT.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/gradientMatrBert.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием градиентного бустинга (метод векторизации -- BERT). }
	\label{img:gradientMatrBert}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/gradientMetricsBert.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием градиентного бустинга (метод векторизации -- BERT). }
	\label{img:gradientMetricsBert}
\end{figure}
\pagebreak



\subsubsection{Метод случайного леса }

Параметры модели при применении метода векторизации <<мешок слов>>:
\begin{itemize}
	\item максимальная глубина -- определяет максимальную глубину дерева решений --~300;
	\item максимальное количество признаков -- определяет максимальное количество признаков, используемых для разбиения узла дерева решений, может принимать значение функции --~$log_2$;
	\item количество классификаторов в ансамбле -- определяет количество деревьев, используемых в алгоритме, --~850.
\end{itemize}

На рисунке \ref{img:randomMatrBag} представлены матрицы ошибок, полученные с использованием метода случайного леса, метод векторизации -- <<мешок слов>>.

На рисунке \ref{img:randomMetricsBag} представлены оценки классификатора, полученные с использованием метода случайного леса, метод векторизации -- <<мешок слов>>.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/randomMatrBag.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием метода случайного леса (метод векторизации -- <<мешок слов>>). }
	\label{img:randomMatrBag}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/randomMetricsBag.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием метода случайного леса (метод векторизации --  <<мешок слов>>). }
	\label{img:randomMetricsBag}
\end{figure}
\pagebreak


Параметры модели при применении векторизации BERT:
\begin{itemize}
	\item максимальная глубина -- отсутствует;
	\item максимальное количество признаков -- $log_2$;
	\item количество классификаторов в ансамбле -- 2600.
\end{itemize}

На рисунке \ref{img:randomMatrBert} представлены матрицы ошибок, полученные с использованием метода случайного леса, метод векторизации -- BERT.

На рисунке \ref{img:randomMetricsBert} представлены оценки классификатора, полученные с использованием метода случайного леса, метод векторизации -- BERT.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/randomMatrBert.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием метода случайного леса (метод векторизации -- BERT). }
	\label{img:randomMatrBert}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/randomMetricsBert.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием метода случайного леса (метод векторизации -- BERT). }
	\label{img:randomMetricsBert}
\end{figure}
\pagebreak



\subsubsection{Метод опорных векторов }

Параметры модели при применении метода векторизации <<мешок слов>>:
\begin{itemize}
	\item регуляризационный параметр -- определяет степень регуляризации модели -- 7.0;
	\item ядро -- определяет тип ядра, используемого в модели -- RBF (радиальное базисной функции);
	\item коэффициент ядра -- определяет <<ширину>> ядра -- значение вычисляется как обратная величина произведения количества признаков на дисперсию признаков.
\end{itemize}

На рисунке \ref{img:svcMatrBag} представлены матрицы ошибок, полученные с использованием метода опорных векторов, метод векторизации -- <<мешок слов>>.

На рисунке \ref{img:svcMetricsBag} представлены оценки классификатора, полученные с использованием метода опорных векторов, метод векторизации -- <<мешок слов>>.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/svcMatrBag.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием метода опорных векторов (метод векторизации -- <<мешок слов>>). }
	\label{img:svcMatrBag}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/svcMetricsBag.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием метода опорных векторов (метод векторизации --  <<мешок слов>>). }
	\label{img:svcMetricsBag}
\end{figure}
\pagebreak


Параметры модели при применении векторизации BERT:
\begin{itemize}
	\item регуляризационный параметр -- 1.5;
	\item ядро -- линейное;
	\item коэффициент ядра -- значение вычисляется как обратная величина произведения количества признаков на дисперсию признаков.
\end{itemize}

На рисунке \ref{img:svcMatrBert} представлены матрицы ошибок, полученные с использованием метода опорных векторов, метод векторизации -- BERT.

На рисунке \ref{img:svcMetricsBert} представлены оценки классификатора, полученные с использованием метода опорных векторов, метод векторизации -- BERT.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/svcMatrBert.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием метода опорных векторов (метод векторизации -- BERT). }
	\label{img:svcMatrBert}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/svcMetricsBert.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием метода опорных векторов (метод векторизации -- BERT). }
	\label{img:svcMetricsBert}
\end{figure}
\pagebreak



\subsubsection{Метод K-ближайших соседей }

Параметры модели при применении метода векторизации <<мешок слов>>:
\begin{itemize}
	\item количество образцов в листе дерева -- 4;
	\item метрика расстояния -- евклидово расстояние;
	\item количество ближайших соседей -- 5;
	\item метод вычисления весов ближайших соседей -- веса, обратно пропорциональные расстоянию до соседа.
\end{itemize}

На рисунке \ref{img:knnMatrBag} представлены матрицы ошибок, полученные с использованием метода K-ближайших соседей, метод векторизации -- <<мешок слов>>.

На рисунке \ref{img:knnMetricsBag} представлены оценки классификатора, полученные с использованием метода K-ближайших соседей, метод векторизации -- <<мешок слов>>.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/knnMatrBag.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием метода K-ближайших соседей (метод векторизации -- <<мешок слов>>). }
	\label{img:knnMatrBag}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/knnMetricsBag.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием метода K-ближайших соседей (метод векторизации --  <<мешок слов>>). }
	\label{img:knnMetricsBag}
\end{figure}
\pagebreak


Параметры модели при применении векторизации BERT:
\begin{itemize}
	\item количество образцов в листе дерева -- 1;
	\item метрика расстояния -- евклидово расстояние;
	\item количество ближайших соседей -- 6;
	\item метод вычисления весов ближайших соседей -- веса, обратно пропорциональные расстоянию до соседа.
\end{itemize}

На рисунке \ref{img:knnMatrBert} представлены матрицы ошибок, полученные с использованием метода K-ближайших соседей, метод векторизации -- BERT.

На рисунке \ref{img:knnMetricsBert} представлены оценки классификатора, полученные с использованием метода K-ближайших соседей, метод векторизации -- BERT.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/knnMatrBert.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием метода K-ближайших соседей (метод векторизации -- BERT). }
	\label{img:knnMatrBert}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/knnMetricsBert.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием метода K-ближайших соседей (метод векторизации -- BERT). }
	\label{img:knnMetricsBert}
\end{figure}
\pagebreak



\subsubsection{Логистическая регрессия}

Параметры модели при применении метода векторизации <<мешок слов>>:
\begin{itemize}
	\item регуляризационный параметр -- 2.2;
	\item веса классов -- сбалансированно;
	\item штраф -- определяет тип штрафа, используемого для регуляризации -- сумма квадратов весов модели, умноженных на гиперпараметр регуляризации;
	\item алгоритм оптимизации -- liblinear.
\end{itemize}

На рисунке \ref{img:logicMatrBag} представлены матрицы ошибок, полученные с использованием логистической регрессии, метод векторизации -- <<мешок слов>>.

На рисунке \ref{img:logicMetricsBag} представлены оценки классификатора, полученные с использованием логистической регрессии, метод векторизации -- <<мешок слов>>.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/logicMatrBag.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием логистической регрессии (метод векторизации -- <<мешок слов>>). }
	\label{img:logicMatrBag}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/logicMetricsBag.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием логистической регрессии (метод векторизации --  <<мешок слов>>). }
	\label{img:logicMetricsBag}
\end{figure}
\pagebreak


Параметры модели при применении векторизации BERT:
\begin{itemize}
	\item регуляризационный параметр -- 2.1;
	\item веса классов -- сбалансированно;
	\item штраф -- сумма квадратов весов модели, умноженных на гиперпараметр регуляризации;
	\item алгоритм оптимизации -- liblinear.
\end{itemize}

На рисунке \ref{img:logicMatrBert} представлены матрицы ошибок, полученные с использованием логистической регрессии, метод векторизации -- BERT.

На рисунке \ref{img:logicMetricsBert} представлены оценки классификатора, полученные с использованием логистической регрессии, метод векторизации -- BERT.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/logicMatrBert.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием логистической регрессии (метод векторизации -- BERT). }
	\label{img:logicMatrBert}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/logicMetricsBert.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием логистической регрессии (метод векторизации -- BERT). }
	\label{img:logicMetricsBert}
\end{figure}
\pagebreak



\subsubsection{Перцептрон}

Параметры модели при применении метода векторизации <<мешок слов>>:
\begin{itemize}
	\item скорость обучения -- 0.0001;
	\item максимальное количество итераций при обучении -- 30;
	\item штраф -- сумма квадратов весов модели, умноженных на гиперпараметр регуляризации.
\end{itemize}

На рисунке \ref{img:perceptronMatrBag} представлены матрицы ошибок, полученные с использованием перцептрона, метод векторизации -- <<мешок слов>>.

На рисунке \ref{img:perceptronMetricsBag} представлены оценки классификатора, полученные с использованием перцептрона, метод векторизации -- <<мешок слов>>.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/perceptronMatrBag.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием перцептрона (метод векторизации -- <<мешок слов>>). }
	\label{img:perceptronMatrBag}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/perceptronMetricsBag.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием перцептрона (метод векторизации --  <<мешок слов>>). }
	\label{img:perceptronMetricsBag}
\end{figure}
\pagebreak


Параметры модели при применении векторизации BERT:
\begin{itemize}
	\item скорость обучения -- 0.0001;
	\item максимальное количество итераций при обучении -- 30;
	\item штраф -- абсолютное значение коэффициентов модели.
\end{itemize}

На рисунке \ref{img:perceptronMatrBert} представлены матрицы ошибок, полученные с использованием перцептрона, метод векторизации -- BERT.

На рисунке \ref{img:perceptronMetricsBert} представлены оценки классификатора, полученные с использованием перцептрона, метод векторизации -- BERT.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{inc/plots/perceptronMatrBert.pdf}
	\caption{ Матрицы ошибок в зависимости от номера разбиения, полученные с использованием перцептрона (метод векторизации -- BERT). }
	\label{img:perceptronMatrBert}
\end{figure}
\pagebreak

\begin{figure}[H]
	\centering
	\includegraphics[height=23cm]{inc/plots/perceptronMetricsBert.pdf}
	\caption{ Оценки классификатора в зависимости от номера разбиения, полученные с использованием перцептрона (метод векторизации -- BERT). }
	\label{img:perceptronMetricsBert}
\end{figure}
\pagebreak

\subsection*{Вывод}

По представленным матрицам ошибок можно увидеть, что все методы, кроме случайного леса (BERT), метода опорных векторов (оба варианта векторизации) и перцептрона (оба варианта), в большинстве своем в 2 раза чаще определяют обычное сообщение как суицидальное. Метод опорных векторов имеет более распределенные матрицы ошибок. Самые частые ошибки в определении обычных сообщений совершал метод К-ближайших соседей. Перцептрон на каждом из разбиений мог либо хуже распознавать суицидальные, либо хуже распознавать обычные сообщения.

В таблицах \ref{table:result1} и \ref{table:result2} приведены результаты проведенного исследования, в которых для каждого алгоритма выделены лучшие показатели каждой метрики.

Из таблиц видно, что лучшим средним показателем метрик точности, F1-меры и ROC-AUC обладает метод случайного леса с использованием BERT-векторизации.
Его метрика точности достигла показателя $0.888$, F1-мера -- $0.886$, а ROC-AUC -- $0.949$.
При этом на втором месте располагается тот же метод, но с использованием векторизации <<Мешок слов>>, относительно первого метода его точность уступает на $\approx 0.4\%$, F1-мера -- на $\approx 1.4\%$, а ROC-AUC -- на $\approx 0.2\%$. 
На третьем месте располагается логистическая регрессия с использованием BERT-векторизации, его точность ниже на $\approx 1.6\%$, F1-мера -- на $\approx 1.9\%$, а ROC-AUC -- на $\approx 0.7\%$. 
Таким образом, в качестве используемой модели в задаче распознавания паттернов суицидального поведения человека по суицидальным сообщениям лучше всего воспользоваться именно методом случайного леса с указанными в исследовании параметрами.

Стоит отметить, что выбранный метод также в $\approx 1.5$ раза чаще ошибочно интерпретирует обычные сообщения как суицидальные, чем суицидальные как обычные. Данный факт не относится к проблеме модели, которая может помешать работе системы в силу того, что распознавание суицидальных сообщений для нее играет первостепенную роль.

Кроме того, с использованием полученной информации можно предложить использовать ансамбль задействованных в исследовании моделей, так как результаты их работы имеют достаточно высокие показатели F1-меры в сбалансированном наборе данных.

\begin{table}[H]
	\begin{center}
		\captionsetup{justification=centering}
		\caption{\label{table:result1} Результаты исследования}
		\begin{tabular}{|p{3cm}|p{4cm}|p{2.4cm}|p{2.4cm}|p{2.4cm}|}
				\hline
			Алгоритм & Векторизация & Точность & F1-мера & ROC-AUC \\
				\hline\hline
			
			\multirow{10}{*}{\shortstack[l]{Градиентный \\ бустинг}} 
& <<Мешок слов>> & 0.858 & 0.849 & 0.926 \\
				&& 0.836 & 0.830 & 0.909 \\
				&& 0.854 & 0.841 & 0.902 \\
				&& 0.864 & 0.854 & 0.926 \\
				\cline{2-5} & \textit{среднее} & \textit{0.853} & \textit{0.844} & \textit{0.916} \\
			\cline{2-5}
		  & BERT & 0.868 & 0.849 & 0.934 \\
				&& 0.852 & 0.840 & 0.918 \\
				&& 0.870 & 0.852 & 0.924 \\
				&& 0.890 & 0.876 & 0.939 \\
				\cline{2-5} & \textit{среднее} & \textit{0.870} & \textit{0.854} & \textit{0.929} \\
			\hline\hline
			
			\multirow{8}{*}{\shortstack[l]{Случайный \\ лес}} 
& <<Мешок слов>> & 0.888 & 0.876 & 0.951 \\
				&& 0.876 & 0.858 & 0.942 \\
				&& 0.884 & 0.881 & 0.937 \\
				&& 0.892 & 0.877 & 0.959 \\
				\cline{2-5} & \textit{среднее} & \textit{0.885} & \textit{0.873} & \textit{0,947} \\
			\cline{2-5}
		  & BERT & 0.886 & 0.884 & 0.954 \\
				&& 0.888 & 0.884 & 0.946 \\
				&& 0.878 & 0.872 & 0.936 \\
				&& 0.900 & 0.902 & 0.960 \\
				\cline{2-5} & \textit{среднее} & \textbf{\textit{0.888}} & \textbf{\textit{0.886}} & \textbf{\textit{0.949}} \\
			\hline\hline
			
			\multirow{8}{*}{\shortstack[l]{Метод\\опорных\\векторов}} 
& <<Мешок слов>> & 0.850 & 0.851 & 0.924 \\
				&& 0.848 & 0.847 & 0.920 \\
				&& 0.824 & 0.819 & 0.899 \\
				&& 0.864 & 0.862 & 0.918 \\
				\cline{2-5} & \textit{среднее} & \textit{0.847} & \textit{0.845} & \textit{0.915} \\
			\cline{2-5}
		  & BERT & 0.864 & 0.865 & 0.930 \\
				&& 0.850 & 0.850 & 0.920 \\
				&& 0.848 & 0.844 & 0.919 \\
				&& 0.886 & 0.884 & 0.928 \\
				\cline{2-5} & \textit{среднее} & \textit{0.862} & \textit{0.861} & \textit{0.924} \\
					
			\hline
		\end{tabular}
	\end{center}
\end{table}

\begin{table}[H]
	\begin{center}
		\captionsetup{justification=centering}
		\caption{\label{table:result2} Результаты исследования}
		\begin{tabular}{|p{3cm}|p{4cm}|p{2.4cm}|p{2.4cm}|p{2.4cm}|}
				\hline
			Алгоритм & Векторизация & Точность & F1-мера & ROC-AUC \\
				\hline\hline
				
			\multirow{8}{*}{\shortstack[l]{Метод\\К-ближайших\\соседей}} 
& <<Мешок слов>> & 0.742 & 0.692 & 0.854 \\
				&& 0.750 & 0.691 & 0.844 \\
				&& 0.738 & 0.678 & 0.845 \\
				&& 0.778 & 0.754 & 0.874 \\
				\cline{2-5} & \textit{среднее} & \textit{0.752} & \textit{0.704} & \textit{0.854} \\
			\cline{2-5}
		  & BERT & 0.772 & 0.749 & 0.868 \\
				&& 0.762 & 0.740 & 0.831 \\
				&& 0.720 & 0.696 & 0.816 \\
				&& 0.778 & 0.761 & 0.853 \\
				\cline{2-5} & \textit{среднее} & \textit{0.758} & \textit{0.737} & \textit{0.842} \\
			\hline\hline
			
			\multirow{8}{*}{\shortstack[l]{Логистическая\\регрессия}} 
& <<Мешок слов>> & 0.864 & 0.858 & 0.947 \\
				&& 0.860 & 0.853 & 0.939 \\
				&& 0.862 & 0.851 & 0.926 \\
				&& 0.880 & 0.872 & 0.936 \\
				\cline{2-5} & \textit{среднее} & \textit{0.867} & \textit{0.859} & \textit{0.937} \\
			\cline{2-5}
		  & BERT & 0.882 & 0.879 & 0.951 \\
				&& 0.854 & 0.849 & 0.941 \\
				&& 0.866 & 0.858 & 0.931 \\
				&& 0.892 & 0.888 & 0.944 \\
				\cline{2-5} & \textit{среднее} & \textit{0.874} & \textit{0.869} & \textit{0.942} \\
			\hline\hline
			
			\multirow{8}{*}{\shortstack[l]{Перцептрон}} 
& <<Мешок слов>> & 0.868 & 0.871 & 0.931 \\
				&& 0.828 & 0.833 & 0.913 \\
				&& 0.828 & 0.831 & 0.896 \\
				&& 0.826 & 0.827 & 0.909 \\
				\cline{2-5} & \textit{среднее} & \textit{0.838} & \textit{0.841} & \textit{0.912} \\
			\cline{2-5}
		  & BERT & 0.870 & 0.873 & 0.939 \\
				&& 0.826 & 0.832 & 0.922 \\
				&& 0.848 & 0.850 & 0.925 \\
				&& 0.868 & 0.872 & 0.938 \\
				\cline{2-5} & \textit{среднее} & \textit{0.853} & \textit{0.857} & \textit{0.931} \\
					
			\hline
		\end{tabular}
	\end{center}
\end{table}