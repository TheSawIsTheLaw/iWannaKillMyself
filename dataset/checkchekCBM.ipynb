{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "589e7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# sklearn\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          plot_place=[0, 0, 0]):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.subplot(*plot_place)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6fa60bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>встаём завтра в 8 утра и делаем все дела</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>меня позвали на суши. и боюсь и хочу. согласил...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>валя &lt;emoji&gt;Skull&lt;/emoji&gt;</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>то есть вы не пишете на столько бессмысленную ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Не знаю почему никто не сделал или я не нашëл ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5952</th>\n",
       "      <td>у нас ещё сильнее снег пошёл&lt;emoji&gt;Grinning fa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>Я пытаюсь в этих ваших китайских новеллах\\nНаз...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>Я сейчас живу одна и вы видели счастье на моём...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>у меня уже спрашивают с сарказмом я говорю или...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>&lt;emoji&gt;Blue heart&lt;/emoji&gt;г&lt;emoji&gt;Blue heart&lt;/e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  class\n",
       "0              встаём завтра в 8 утра и делаем все дела    0.0\n",
       "1     меня позвали на суши. и боюсь и хочу. согласил...    0.0\n",
       "2                             валя <emoji>Skull</emoji>    0.0\n",
       "3     то есть вы не пишете на столько бессмысленную ...    0.0\n",
       "4     Не знаю почему никто не сделал или я не нашëл ...    0.0\n",
       "...                                                 ...    ...\n",
       "5952  у нас ещё сильнее снег пошёл<emoji>Grinning fa...    0.0\n",
       "5953  Я пытаюсь в этих ваших китайских новеллах\\nНаз...    0.0\n",
       "5954  Я сейчас живу одна и вы видели счастье на моём...    0.0\n",
       "5955  у меня уже спрашивают с сарказмом я говорю или...    0.0\n",
       "5957  <emoji>Blue heart</emoji>г<emoji>Blue heart</e...    0.0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"presuicidal_signals_dataset_twitter.csv\",delimiter=\"|\")\n",
    "non_suicidal = data.loc[data['label'] == 5].head(5000)[['text', 'label']].rename(columns={'label': 'class'}).replace(5, 0)\n",
    "non_suicidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2d16c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/rxp2phv12xl4m1wk92ksqgxr0000gn/T/ipykernel_1565/1522899303.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = non_suicidal.append(suicidal)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"own_shit.csv\")\n",
    "suicidal = data[['text', 'class']]\n",
    "\n",
    "data = non_suicidal.append(suicidal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ed02d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda string: \" \".join(remove_emojis(string)).split(\"\\n\"))\n",
    "data.to_csv(\"suicidal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "018f96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_suicidal['text'] = non_suicidal['text'].apply(lambda it: remove_emojis(it))\n",
    "non_suicidal.to_csv(\"non_suicidal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2bed5a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>[Н е т   н и   о д н о й   п р и ч и н ы   ж и...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>[м ы   в с е   л ю д и н и ,   у   н а с   у  ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>[Н е   в и ж у   с м ы с л а   в   с в о е й  ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>[П о м о г и т е ,   к а к   и з б а в и т ь с...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>[Я   н е   в и ж у   с м ы с л   ж и з н и   ,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>[О т н о ш е н и я   Ч у и   и   Ж е н и   н а...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>[М о ж е т е   л и   в ы   п р е д с т а в и т...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>[Г о с п о д и ,   п р о с т и   м н е   м о е...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>[С е г о д н я   т о т   с а м ы й   д е н ь ,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>[С а м ы й   п и * д е ц ,   к о г д а   н е  ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  class\n",
       "413  [Н е т   н и   о д н о й   п р и ч и н ы   ж и...    1.0\n",
       "350  [м ы   в с е   л ю д и н и ,   у   н а с   у  ...    0.0\n",
       "984  [Н е   в и ж у   с м ы с л а   в   с в о е й  ...    1.0\n",
       "584  [П о м о г и т е ,   к а к   и з б а в и т ь с...    1.0\n",
       "152  [Я   н е   в и ж у   с м ы с л   ж и з н и   ,...    1.0\n",
       "..                                                 ...    ...\n",
       "864  [О т н о ш е н и я   Ч у и   и   Ж е н и   н а...    0.0\n",
       "671  [М о ж е т е   л и   в ы   п р е д с т а в и т...    1.0\n",
       "143  [Г о с п о д и ,   п р о с т и   м н е   м о е...    1.0\n",
       "709  [С е г о д н я   т о т   с а м ы й   д е н ь ,...    1.0\n",
       "108  [С а м ы й   п и * д е ц ,   к о г д а   н е  ...    1.0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy3 import MorphAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "an = MorphAnalyzer(lang='ru')\n",
    "stops = stopwords.words('russian')\n",
    "\n",
    "def getClearSentences(sentences):\n",
    "    return \" \".join(str(s) + \"\" for s in (an.normal_forms(y)[0] for y in filter(lambda x: x not in stops, nltk.word_tokenize(str(sentences)))))\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: getClearSentences(x))\n",
    "corpus = data['text']\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_data = vectorizer.fit_transform(corpus)\n",
    "vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e378d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_data = data['class'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def confusionMatrices(estimator, classes = []):\n",
    "    splits = 3\n",
    "    kf = KFold(n_splits=splits)\n",
    "    n = 1\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for train, test in kf.split(vectorized_data):\n",
    "        estimator.fit(vectorized_data[train], classes_data.iloc[train].values.ravel())\n",
    "        predicted = estimator.predict(vectorized_data[test])\n",
    "\n",
    "        matrix = confusion_matrix(classes_data.iloc[test], predicted)\n",
    "        plot_confusion_matrix(matrix, classes, plot_place=[splits, 1, n])\n",
    "        n += 1\n",
    "\n",
    "def crossScores(estimator):\n",
    "    crossScoreF = cross_val_score(estimator, scoring='f1_micro', X=vectorized_data, y=classes_data.tolist(), cv=3)\n",
    "\n",
    "    plt.plot(crossScoreF)\n",
    "    plt.title(\"f1 micro\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearch(estimator, paramGrid):\n",
    "\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(vectorized_data, classes_data, test_size=0.2)\n",
    "\n",
    "    searchCV = GridSearchCV(estimator, param_grid=paramGrid)\n",
    "    searchCV.fit(xTrain, yTrain)\n",
    "    print(searchCV.best_params_)\n",
    "    searchCV.cv_results_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee5066cc",
   "metadata": {},
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = GradientBoostingClassifier()\n",
    "gridSearch(estimator, paramGrid={'learning_rate': [0.1, 0.5, 1, 2], 'min_samples_split': [2, 3, 6], 'n_estimators': [20, 40, 60]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b17da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = GradientBoostingClassifier(learning_rate=0.4, min_samples_split=3, n_estimators=60)\n",
    "confusionMatrices(estimator=estimator, classes=[\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict(vectorizer.transform([getClearSentences(\"Впизду все это, заебало нахуй. Зачем я здесь? Что мне уготовлено? проще вздернуться\")]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68048634",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e089f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "gridSearch(estimator, paramGrid={'n_jobs': [-1],'n_estimators': [1, 10, 100, 500], 'max_depth':[None, 10, 100], 'class_weight': [None, 'balanced', 'balanced_subsample']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(class_weight='balanced_subsample', n_jobs=-1, n_estimators=500, max_depth=100)\n",
    "plt.figure(figsize=(20, 10))\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afd97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier(n_jobs=-1, n_estimators=500)\n",
    "crossScores(estimator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d1d35bf",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "estimator = SVC()\n",
    "gridSearch(estimator, paramGrid={'C': [1.0, 2.0, 10.0, 100.0], 'degree': [3, 4, 6, 7], 'kernel': ['linear', 'poly', 'rbf']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVC(C=1.0, degree=3, kernel='linear')\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a96336",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7042b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
