{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589e7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# sklearn\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Матрица ошибок',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          plot_place=[0, 0, 0]):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.subplot(*plot_place)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Истина')\n",
    "    plt.xlabel('Прогноз')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f08370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SPLIT_NUMBER = 4\n",
    "\n",
    "def confusionMatrices(estimator, classes = []):\n",
    "    classes_data = data['class'].apply(lambda x: int(x))\n",
    "    splits = SPLIT_NUMBER\n",
    "    kf = KFold(n_splits=splits)\n",
    "    n = 1\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for train, test in kf.split(vectorized_data):\n",
    "        estimator.fit(vectorized_data[train], classes_data.iloc[train].values.ravel())\n",
    "        predicted = estimator.predict(vectorized_data[test])\n",
    "\n",
    "        matrix = confusion_matrix(classes_data.iloc[test], predicted)\n",
    "        plot_confusion_matrix(matrix, classes, plot_place=[int(splits / 2) + splits % 2, 2, n])\n",
    "        n += 1\n",
    "\n",
    "def crossScores(estimator):\n",
    "    classes_data = data['class'].apply(lambda x: int(x))\n",
    "    crossScoreAccuracy = cross_val_score(estimator, scoring='accuracy', X=vectorized_data, y=classes_data.tolist(), cv=SPLIT_NUMBER)\n",
    "    crossScoreF = cross_val_score(estimator, scoring='f1', X=vectorized_data, y=classes_data.tolist(), cv=SPLIT_NUMBER)\n",
    "    crossScoreRocAuc = cross_val_score(estimator, scoring='roc_auc', X=vectorized_data, y=classes_data.tolist(), cv=SPLIT_NUMBER)\n",
    "\n",
    "    fig, axs = plt.subplots(SPLIT_NUMBER, figsize=(10, 20))\n",
    "    \n",
    "    axs[0].plot(crossScoreAccuracy)\n",
    "    axs[0].set_title(\"Точность\")\n",
    "    axs[0].set(xlabel='Порядковый номер разбиения', ylabel='Значение метрики')\n",
    "\n",
    "    axs[1].plot(crossScoreF)\n",
    "    axs[1].set_title(\"F1\")\n",
    "    axs[1].set(xlabel='Порядковый номер разбиения', ylabel='Значение метрики')\n",
    "    \n",
    "    axs[2].plot(crossScoreRocAuc)\n",
    "    axs[2].set_title(\"ROC AUC\")\n",
    "    axs[2].set(xlabel='Порядковый номер разбиения', ylabel='Значение метрики')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearch(vectorized_data, estimator, paramGrid):\n",
    "    classes_data = data['class'].apply(lambda x: int(x))\n",
    "    \n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(vectorized_data, classes_data, test_size=1 / SPLIT_NUMBER)\n",
    "\n",
    "    searchCV = GridSearchCV(estimator, param_grid=paramGrid, n_jobs=-1, scoring='f1', refit=False)\n",
    "    searchCV.fit(xTrain, yTrain)\n",
    "    print(searchCV.best_params_)\n",
    "    searchCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bed5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/rxp2phv12xl4m1wk92ksqgxr0000gn/T/ipykernel_3167/1614600193.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = suicidal.append(non_suicidal)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220</td>\n",
       "      <td>почему в этой жизни у всех всё есть кроме меня...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>1358</td>\n",
       "      <td>щас бы умывашкой для лица за 2к мыть ноги</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>1034</td>\n",
       "      <td>которую вообще-то должна же делать я, а это зн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>783</td>\n",
       "      <td>Хотите узнать, насколько я лох по жизни? После...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1860</td>\n",
       "      <td>сегодня был такой ужасный день. он начаться с ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1277</td>\n",
       "      <td>ахахахха как он не хотел спасать стариков но с...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1565</td>\n",
       "      <td>у меня появилось мыло для бровей, поэтому я ул...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>542</td>\n",
       "      <td>меня сфоткали на планерке...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>715</td>\n",
       "      <td>Я только угроза для других...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>502</td>\n",
       "      <td>Жизнь уже никогда не наладится, мне не светит ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2499 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  class\n",
       "220          220  почему в этой жизни у всех всё есть кроме меня...      1\n",
       "1075        1358          щас бы умывашкой для лица за 2к мыть ноги      0\n",
       "816         1034  которую вообще-то должна же делать я, а это зн...      0\n",
       "624          783  Хотите узнать, насколько я лох по жизни? После...      0\n",
       "1471        1860  сегодня был такой ужасный день. он начаться с ...      0\n",
       "...          ...                                                ...    ...\n",
       "1004        1277  ахахахха как он не хотел спасать стариков но с...      0\n",
       "1234        1565  у меня появилось мыло для бровей, поэтому я ул...      0\n",
       "431          542                       меня сфоткали на планерке...      0\n",
       "715          715                      Я только угроза для других...      1\n",
       "502          502  Жизнь уже никогда не наладится, мне не светит ...      1\n",
       "\n",
       "[2499 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "suicidal = pd.read_csv(\"PreparedDatasets/suicidal.csv\")\n",
    "non_suicidal = pd.read_csv(\"PreparedDatasets/non_suicidal.csv\").head(1500)\n",
    "\n",
    "data = suicidal.append(non_suicidal)\n",
    "\n",
    "data = shuffle(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220           почему жизнь всё кроме ? проказить родиться\n",
       "1075                    сейчас умывашка лицо 2к мыть нога\n",
       "816     который вообще-то должный делать , это значит ...\n",
       "624     хотеть узнать , насколько лох жизнь ? после 12...\n",
       "1471    сегодня ужасный день . начаться делать закончи...\n",
       "                              ...                        \n",
       "1004      ахахахха хотеть спасать старик сердце приказать\n",
       "1234    появиться мыло бровь , поэтому уложить волос н...\n",
       "431                                 сфоткать планёрка ...\n",
       "715                                   я угроза другой ...\n",
       "502     жизнь наладиться , светить кроме учёба какой-н...\n",
       "Name: text, Length: 2499, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymorphy3 import MorphAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "an = MorphAnalyzer(lang='ru')\n",
    "stops = stopwords.words('russian')\n",
    "\n",
    "def getClearSentences(sentences):\n",
    "    return \" \".join(str(s) + \"\" for s in (an.normal_forms(y)[0] for y in filter(lambda x: x not in stops, nltk.word_tokenize(str(sentences)))))\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: getClearSentences(x))\n",
    "corpus = data['text']\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a05a03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2499x9470 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 48142 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_data_bag = vectorizer.fit_transform(corpus)\n",
    "vectorized_data_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "757c3e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2499x83818 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 95770 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from pandas import DataFrame\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('cointegrated/rubert-tiny2')\n",
    "\n",
    "bert_tokenized = corpus.apply(lambda ser: tokenizer.convert_tokens_to_ids(tokenizer.tokenize(ser)))\n",
    "bert_list = bert_tokenized.tolist()\n",
    "\n",
    "nRows = len(bert_list)\n",
    "nCols = max(max(row) if (len(row) > 0) else 0 for row in bert_list) + 1\n",
    "\n",
    "dataIn = []\n",
    "indices = []\n",
    "indptr = [0]\n",
    "\n",
    "for row in bert_list:\n",
    "    indices.extend(row)\n",
    "    dataIn.extend([1] * len(row))\n",
    "    indptr.append(len(indices))\n",
    "\n",
    "vectorized_data_bert = csr_matrix((dataIn, indices, indptr), shape=(nRows, nCols))\n",
    "vectorized_data_bert"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee5066cc",
   "metadata": {},
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b8079",
   "metadata": {},
   "source": [
    "## Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67df9fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1, 'min_samples_split': 3, 'n_estimators': 60}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = GradientBoostingClassifier()\n",
    "gridSearch(vectorized_data_bag, estimator, paramGrid={'learning_rate': [0.1, 0.5, 1, 2], 'min_samples_split': [2, 3, 6], 'n_estimators': [20, 40, 60]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b17da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = GradientBoostingClassifier(learning_rate=0.5, min_samples_split=6, n_estimators=60)\n",
    "confusionMatrices(estimator=estimator, classes=[\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict(vectorizer.transform([getClearSentences(\"Ща сдохну от смеха\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c8f8c",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = GradientBoostingClassifier()\n",
    "gridSearch(vectorized_data_bert, estimator, paramGrid={'learning_rate': [0.1, 0.5, 1, 2], 'min_samples_split': [2, 3, 6], 'n_estimators': [20, 40, 60]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "estimator = GradientBoostingClassifier(learning_rate=0.5, min_samples_split=6, n_estimators=60)\n",
    "confusionMatrices(estimator=estimator, classes=[\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6adbc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2bc4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict(vectorizer.transform([getClearSentences(\"Ща сдохну от смеха\")]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68048634",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce74aa",
   "metadata": {},
   "source": [
    "## Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e089f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "gridSearch(vectorized_data_bag, estimator, paramGrid={'n_jobs': [-1],'n_estimators': [50, 100, 150], 'max_depth':[50, 100, 150], 'class_weight': [None, 'balanced', 'balanced_subsample'], 'max_features': ['sqrt', 'log2', None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(class_weight=None, max_depth=100, max_features='sqrt', min_samples_leaf=1, n_estimators=50, n_jobs=-1)\n",
    "plt.figure(figsize=(20, 10))\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afd97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada65bd8",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "gridSearch(vectorized_data_bert, estimator, paramGrid={'n_jobs': [-1],'n_estimators': [50, 100, 150], 'max_depth':[50, 100, 150], 'class_weight': [None, 'balanced', 'balanced_subsample'], 'max_features': ['sqrt', 'log2', None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(class_weight=None, max_depth=100, max_features='sqrt', min_samples_leaf=1, n_estimators=50, n_jobs=-1)\n",
    "plt.figure(figsize=(20, 10))\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d1d35bf",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f64bd9",
   "metadata": {},
   "source": [
    "## Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "estimator = SVC()\n",
    "gridSearch(vectorized_data_bag, estimator, paramGrid={'C': [1.0, 2.0, 10.0, 100.0], 'degree': [3, 4, 6, 7], 'kernel': ['linear', 'poly', 'rbf']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVC(C=1.0, degree=3, kernel='linear')\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a96336",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b4f38",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "estimator = SVC()\n",
    "gridSearch(vectorized_data_bert, estimator, paramGrid={'C': [1.0, 2.0, 10.0, 100.0], 'degree': [3, 4, 6, 7], 'kernel': ['linear', 'poly', 'rbf']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVC(C=1.0, degree=3, kernel='linear')\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4add78",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f9a9c",
   "metadata": {},
   "source": [
    "## Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7042b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "estimator = KNeighborsClassifier()\n",
    "print(gridSearch(vectorized_data_bag, estimator, paramGrid={'n_neighbors': [3, 5, 10], 'weights': ['uniform', 'distance'], 'leaf_size': [20, 30, 40], 'p': [1, 2, 4], 'metric': ['euclidean', 'manhattan']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4bde4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier(n_neighbors=3, weights='distance', leaf_size=20, p=1, metric='euclidean')\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9551a",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "estimator = KNeighborsClassifier()\n",
    "print(gridSearch(vectorized_data_bert, estimator, paramGrid={'n_neighbors': [3, 5, 10], 'weights': ['uniform', 'distance'], 'leaf_size': [20, 30, 40], 'p': [1, 2, 4], 'metric': ['euclidean', 'manhattan']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier(n_neighbors=3, weights='distance', leaf_size=20, p=1, metric='euclidean')\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8ca40",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a541b",
   "metadata": {},
   "source": [
    "## Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "gridSearch(vectorized_data_bag, estimator, paramGrid={'penalty': ['l2'], 'C': [2.1, 2.2, 2.3, 2.4], 'class_weight': [{0: 1, 1: 2}, {0: 2, 1: 1}, 'balanced', None], 'solver': ['lbfgs', 'liblinear', 'newton-ct']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(penalty='l2', C= 2.2, class_weight={0:1, 1:2}, solver='liblinear')\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25580eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972996a",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6532ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "gridSearch(vectorized_data_bert, estimator, paramGrid={'penalty': ['l2'], 'C': [2.1, 2.2, 2.3, 2.4], 'class_weight': [{0: 1, 1: 2}, {0: 2, 1: 1}, 'balanced', None], 'solver': ['lbfgs', 'liblinear', 'newton-ct']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(penalty='l2', C= 2.2, class_weight={0:1, 1:2}, solver='liblinear')\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20218875",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c389c1",
   "metadata": {},
   "source": [
    "## Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "estimator = Perceptron()\n",
    "gridSearch(vectorized_data_bag, estimator, paramGrid={'penalty': ['l2', 'l1', 'elasticnet'], 'alpha': [0.0001, 0.0005, 0.001], 'n_jobs': [-1], 'max_iter': [500, 1000, 1500], 'class_weight': [{0:1, 1:2}, {0:2, 1:1}, 'balanced', None]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Perceptron(alpha=0.0001, class_weight={0:2, 1:1}, max_iter=500, penalty='l1', n_jobs=-1)\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528bb61",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8479b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "estimator = Perceptron()\n",
    "gridSearch(vectorized_data_bert, estimator, paramGrid={'penalty': ['l2', 'l1', 'elasticnet'], 'alpha': [0.0001, 0.0005, 0.001], 'n_jobs': [-1], 'max_iter': [500, 1000, 1500], 'class_weight': [{0:1, 1:2}, {0:2, 1:1}, 'balanced', None]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Perceptron(alpha=0.0001, class_weight={0:2, 1:1}, max_iter=500, penalty='l1', n_jobs=-1)\n",
    "confusionMatrices(estimator, [\"суицидальное\", \"обычное\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossScores(estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
